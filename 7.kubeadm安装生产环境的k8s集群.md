## kubeadm安装生产环境的k8s集群

### 目标

涉及虚拟机

master1:192.168.82.129

master2:192.168.82.130

node:192.168.82.131

### 安装初始化环境

#### 设置ip

```sh
 cat /etc/sysconfig/network-scripts/ifcfg-ens33 
```

```sh
....
BOOTPROTO="static"
DEFROUTE="yes"
....
NAME="ens33"
UUID="11f5df1d-8921-4d5f-9bf1-5eb6894492df"
DEVICE="ens33"
ONBOOT="yes"
IPADDR="192.168.82.129"
NETMASK="255.255.255.0"
GATEWAY="192.168.82.2"
DNS1="8.8.8.8"
DNS2="8.8.4.4"
```

保证三个ip能够正常访问外网，且是固定ip。

#### 修改host

```sh
vim /etc/hosts
```

```sh
192.168.82.129   master1
192.168.82.130   master2
192.168.82.131   node
```

如果没有的设置，初始化kubeadm会提示错误。

#### 关闭防火墙

```sh
systemctl stop firewalld.service &&systemctl disable firewalld.service
```

或者打开端口![image-20220704121537898](7.kubeadm%E5%AE%89%E8%A3%85%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84k8s%E9%9B%86%E7%BE%A4.assets/image-20220704121537898.png)

#### 关闭selinux

```sh
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
```

重启后查看状态

```sh
getenforce
```

#### 关闭交换分区

```sh
vi /etc/fstab
```

注释代码

```sh
#/dev/mapper/centos_master2-swap swap                    swap    defaults        0 0
```

重启后查看状态,swap部分应该为0。

```sh
free -m
```

#### 检查配置

设置原因https://juejin.cn/post/7039164844255215647。不管是 iptables 还是 ipvs 模式，Kubernetes 中访问 service 都会进行 DNAT，将原本访问 ClusterIP:Port 的数据包 DNAT 成 service 的某个 Endpoint (PodIP:Port)

```sh
cat /proc/sys/net/bridge/bridge-nf-call-iptables#默认开启
cat /proc/sys/net/ipv4/ip_forward#默认关闭
```

两个东西必须都开启。

加载模块

```sh
modprobe br_netfilter
```

创建文件

```sh
cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
```

激活配置

```
sysctl -p /etc/sysctl.d/k8s.conf 
```

激活后检查

```sh
cat /proc/sys/net/bridge/bridge-nf-call-iptables#1
cat /proc/sys/net/ipv4/ip_forward#1
```

#### 安装yum源

其中包括base、epel和docker的yum源。

备份旧源

```sh
mkdir /root/repo.bak
cd /etc/yum.repos.d/
mv * /root/repo.bak/
```

上传附录里面的docker-ce.repo和CentOS-base.repo

或者使用下面语句安装docker-ce。

```sh
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```

#### 安装基础镜像

```sh
yum install -y yum-utils device-mapper-persistent-data lvm2 wget net-tools nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel  python-devel epel-release openssh-server socat  ipvsadm conntrack ntpdate telnet rsync chrony
```

#### 安装ipvs

上传附录里面的ipvs.modules文件到`/etc/sysconfig/modules`

```sh
chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs
```

将文件发送到其他节点

```sh
scp /etc/sysconfig/modules/ipvs.modules 192.168.82.130:/etc/sysconfig/modules
scp /etc/sysconfig/modules/ipvs.modules 192.168.82.131:/etc/sysconfig/modules
```

并分别指定

```sh
chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs
```

#### 设置时间

```sh
yum install -y chrony
```

```sh
systemctl start  chronyd
systemctl enable chronyd
systemctl status chronyd
```

修改配置

```sh

# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (http://www.pool.ntp.org/join.html).
#追加源
server time1.aliyun.com iburst
server time.neu.edu.cn iburst
# Record the rate at which the system clock gains/losses time.
driftfile /var/lib/chrony/drift

# Allow the system clock to be stepped in the first three updates
# if its offset is larger than 1 second.
makestep 1.0 3

# Enable kernel synchronization of the real-time clock (RTC).
rtcsync

# Enable hardware timestamping on all interfaces that support it.
#hwtimestamp *

# Increase the minimum number of selectable sources required to adjust
# the system clock.
#minsources 2

# Allow NTP client access from local network.
#allow 192.168.0.0/16

# Serve time even if not synchronized to a time source.
#local stratum 10

# Specify file containing keys for NTP authentication.
#keyfile /etc/chrony.keys

# Specify directory for log files.
logdir /var/log/chrony

# Select which information is logged.
#log measurements statistics tracking                                         
```

```
systemctl restart  chronyd
```

设置UTC时区

```sh
ln -sf /usr/share/zoneinfo/UTC /etc/localtime
```

#### 安装docker

```sh
yum install docker-ce docker-ce-cli containerd.io -y 
systemctl start docker && systemctl enable docker.service && systemctl status docker
```

设置镜像加速

```sh
tee /etc/docker/daemon.json << 'EOF'
{
 "registry-mirrors":["https://rsbud4vc.mirror.aliyuncs.com","https://registry.docker-cn.com","https://docker.mirrors.ustc.edu.cn","https://dockerhub.azk8s.cn","http://hub-mirror.c.163.com","http://qtid6917.mirror.aliyuncs.com", "https://rncxm540.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=systemd"]
} 
EOF
```

重启

```sh
systemctl daemon-reload
systemctl restart docker
systemctl status docker
```

### 安装kube所需要软件包

```sh
yum install -y kubelet-1.20.6 kubeadm-1.20.6 kubectl-1.20.6
```

如果提示没有可安装软件,这个真的有用！！！！

```sh
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum clean all && yum -y makecache
```

设置开机自启，查看状态

```sh
systemctl enable kubelet
systemctl status kubelet
```

注：每个软件包的作用

- Kubeadm:  kubeadm是一个工具，用来初始化k8s集群的
- kubelet:  安装在集群所有节点上，用于启动Pod的
- kubectl:  通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件

### 安装nginx和keepalived

我在一台控制节点和工作节点安装nginx服务

```sh
yum install nginx nginx-mod-stream keepalived -y
```

#### 修改nginx配置文件

```sh
vim /etc/nginx/nginx.conf
```

内容如下

```sh
cat > /etc/nginx/nginx.conf<<EOF

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;

include /usr/share/nginx/modules/*.conf;

events {
    worker_connections 1024;
}

# 四层负载均衡，为两台Master apiserver组件提供负载均衡
stream {

    log_format  main  '$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent';

    access_log  /var/log/nginx/k8s-access.log  main;

    upstream k8s-apiserver {
       server 192.168.82.129:6443;   # xianchaomaster1 APISERVER IP:PORT
       server 192.168.82.128:6443;   # xianchaomaster2 APISERVER IP:PORT

    }
    
    server {
       listen 16443; # 由于nginx与master节点复用，这个监听端口不能是6443，否则会冲突
       proxy_pass k8s-apiserver;
    }
}

http {
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    server {
        listen       80 default_server;
        server_name  _;

        location / {
        }
    }
}
EOF
```

#### 设置keepalived配置文件

##### 主配置文件

将82.131作为主节点

```sh
vim  /etc/keepalived/keepalived.conf 
```

```sh
global_defs { 
   notification_email { 
     acassen@firewall.loc 
     failover@firewall.loc 
     sysadmin@firewall.loc 
   } 
   notification_email_from Alexandre.Cassen@firewall.loc  
   smtp_server 127.0.0.1 
   smtp_connect_timeout 30 
   router_id NGINX_MASTER
} 

vrrp_script check_nginx {
    script "/etc/keepalived/check_nginx.sh"
}

vrrp_instance VI_1 { 
    state MASTER 
    interface ens33  # 修改为实际网卡名
    virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 
    priority 100    # 优先级，备服务器设置 90 
    advert_int 1    # 指定VRRP 心跳包通告间隔时间，默认1秒 
    authentication { 
        auth_type PASS      
        auth_pass 1111 
    }  
    # 虚拟IP
    virtual_ipaddress { 
        192.168.82.199/24
    } 
    track_script {
        check_nginx
    } 
}

```

##### 备配置文件

```sh
global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id NGINX_MASTER
}

vrrp_script check_nginx {
    script "/etc/keepalived/check_nginx.sh"
}

vrrp_instance VI_1 {
    state BACKUP 
    interface ens33  # 修改为实际网卡名
    virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的
    priority  90   # 优先级，备服务器设置 90 
    advert_int 1    # 指定VRRP 心跳包通告间隔时间，默认1秒
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 虚拟IP
    virtual_ipaddress {
        192.168.82.199/24
    }
    track_script {
        check_nginx
    }
}

```



##### 检测nginx脚本

```sh
vim  /etc/keepalived/check_nginx.sh
```

内容

```
#!/bin/bash
count=$(ps -ef |grep nginx | grep sbin | egrep -cv "grep|$$")
if [ "$count" -eq 0 ];then
    systemctl stop keepalived
fi
```

授予执行权限

```
chmod +x  /etc/keepalived/check_nginx.sh
```

#### 启动服务

```sh
systemctl start nginx
systemctl enable nginx
```

如果启动后,`systemctl status nginx`提示

```sh
 nginx: [emerg] bind() to 0.0.0.0:16443 failed (13: Permission denied)
```

应该重启电脑了，selinux需要重启后生效。

```sh
systemctl start keepalived
systemctl enable keepalived
```

当两个节点的服务都启动起来以后，关闭主节点的nginx。那么虚拟ip会进行漂移，且keepalived关闭。可以通过ip addr查看。启动主节点的nginx和keepalived以后，虚拟ip又会回到主节点的ens33。

### 初始化k8s集群

#### 导入镜像包

附录里面存在k8simage-1-20-6.tar.gz，三个节点都需要导入。

```sh
docker load -i k8simage-1-20-6.tar.gz
```

#### 安装k8s集群

```sh
kubeadm init --config kubeadm-config.yaml --ignore-preflight-errors=SystemVerification
```

注：--image-repository registry.aliyuncs.com/google_containers：手动指定仓库地址为registry.aliyuncs.com/google_containers。kubeadm默认从k8s.grc.io拉取镜像，但是k8s.gcr.io访问不到，所以需要指定从registry.aliyuncs.com/google_containers仓库拉取镜像。

安装完毕后，还不够kubectl还没有相关配置。

![image-20220705114852289](7.kubeadm%E5%AE%89%E8%A3%85%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84k8s%E9%9B%86%E7%BE%A4.assets/image-20220705114852289.png)

这还有两种方式

![image-20220705114956276](7.kubeadm%E5%AE%89%E8%A3%85%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84k8s%E9%9B%86%E7%BE%A4.assets/image-20220705114956276.png)

默认配置位置`$HOME/.kube/config`

```sh
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

执行完毕以后

```sh
[root@master1 ~]# kubectl get nodes
NAME      STATUS     ROLES                  AGE   VERSION
master1   NotReady   control-plane,master   30m   v1.20.6
```

提示notReady是因为没有安装网络插件。

#### 追加控制节点

##### kubectl配置

```sh
cd /root && mkdir -p /etc/kubernetes/pki/etcd &&mkdir -p ~/.kube/
```

##### 复制证书

```sh
scp /etc/kubernetes/pki/ca.crt master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/ca.key master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/sa.key master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/sa.pub master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/front-proxy-ca.crt master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/front-proxy-ca.key master2:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/etcd/ca.crt master2:/etc/kubernetes/pki/etcd/
scp /etc/kubernetes/pki/etcd/ca.key master2:/etc/kubernetes/pki/etcd/
```

![image-20220705120508790](7.kubeadm%E5%AE%89%E8%A3%85%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84k8s%E9%9B%86%E7%BE%A4.assets/image-20220705120508790.png)

##### 获取加入集群指令

```sh
kubeadm token create --print-join-command
```

返回结果

```sh
kubeadm join 192.168.82.199:16443 --token fgvx5p.gnbc0wgfulhqf4rd \
    --discovery-token-ca-cert-hash sha256:be6c73ac3e07a37f1c694d3190289f19ac04e13c310cea14f9ea4ef1ccf075b8  --control-plane 
```

第一次执行没有问题，但是如果在拷贝证书以前执行了，证书没有会导致加入集群失败。需要执行语句

```sh
kubeadm reset
```

然后再执行`kubeadm join`